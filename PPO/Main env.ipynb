{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08fd2ddf-29a6-4a9e-9e4c-37ba9fb6a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Agents import Agent\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8faf444-764f-4603-a049-becff69dee9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19114148-4f9d-46da-bf0c-7c392a30a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.10.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from Enviroment import Enviroment\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    '''\n",
    "    Оборочивание класса среды в среду gym\n",
    "    '''\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, obstacle_turn: bool, Total_war: bool, num_obs: int, num_enemy: int, inp_dim: int,\n",
    "                 size_obs, steps_limit, vizualaze = False, head_velocity = 0.01, rew_col = -70,\n",
    "                 rew_win = 100, rew_defeat = -100):\n",
    "        '''\n",
    "        Инициализация класса среды\n",
    "        :param obstacle_turn: (bool) Флаг генерации препятствий\n",
    "        :param vizualaze: (bool) Флаг генерации препятствий\n",
    "        :param Total_war: (bool) Флаг режима игры (с противником или без)\n",
    "        :param steps_limit: (int) Максимальное количество действий в среде за одну игру\n",
    "        '''\n",
    "\n",
    "        self.log_koef = 50\n",
    "        self.ang_Norm_coef = np.pi\n",
    "        self.coords_Norm_coef = 500\n",
    "        \n",
    "        self.inp_dim = inp_dim\n",
    "        \n",
    "        self.rew_col = rew_col\n",
    "        self.rew_win = rew_win\n",
    "        self.rew_defeat = rew_defeat\n",
    "\n",
    "        self.enviroment = Enviroment(obstacle_turn, vizualaze, Total_war,\n",
    "                             head_velocity, num_obs, num_enemy, size_obs, steps_limit,\n",
    "                             rew_col, rew_win, rew_defeat,epsilon = 100,sigma =30)\n",
    "\n",
    "        self.enviroment.reset()\n",
    "\n",
    "        self.action_space = spaces.Discrete(8)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(self.inp_dim, self.inp_dim, 3), dtype=np.uint8)\n",
    "       \n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Метод осуществления шага в среде\n",
    "        :param action: (int) направление движения в среде\n",
    "        :return: dict_state, reward, not done, {}: состояние, реворд, флаг терминального состояния, информация о среде\n",
    "        \"\"\"\n",
    "        state, reward, done, numstep = self.enviroment.step(int(action))\n",
    "\n",
    "        x2 = state.posRobot[0]\n",
    "        y2 = state.posRobot[1]\n",
    "    \n",
    "        x4 = state.target[0,0]\n",
    "        y4 = state.target[0,1]\n",
    "        \n",
    "        \n",
    "        f2 =  state.target[0,2]\n",
    "        f2 = np.deg2rad(f2)\n",
    "        \n",
    "        Ax4, Ay4 = -np.cos(f2), np.sin(f2)\n",
    "        Bx24, By24 = x2 - x4, y2 - y4\n",
    "\n",
    "        dist = - np.sqrt(np.abs((x2-x4)**2 + (y2-y4)**2))\n",
    "        phy = (Ax4*Bx24 + Ay4*By24)/(np.sqrt(Ax4**2 + Ay4**2) * np.sqrt(Bx24**2 + By24**2))\n",
    "        reward_l = phy*(dist+500) * 0.01 * (not done) + np.round(reward, 2).sum()\n",
    "\n",
    "        return state.img, reward_l, done, {}\n",
    "        \n",
    "    def reset(self):\n",
    "        '''\n",
    "        Метод обновления игры\n",
    "        :return: dict_state: состояние\n",
    "        '''\n",
    "        state = self.enviroment.reset()\n",
    "\n",
    "        return state.img\n",
    "\n",
    "    def render(self, model, num_gifs=1):\n",
    "        '''\n",
    "        Метод вывода информации об игре\n",
    "        :param mode:\n",
    "        :return:\n",
    "        '''\n",
    "        for i in range(num_gifs):\n",
    "            \n",
    "            images = []\n",
    "            obs = self.reset()\n",
    "            img = obs['img']# env.render(mode='rgb_array')\n",
    "            done = False\n",
    "                \n",
    "            height, width, layers = img.shape\n",
    "            size = (width,height)\n",
    "            out = cv2.VideoWriter(f\"video{i}.avi\",cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            out.write(img)\n",
    "            while not done:\n",
    "\n",
    "                action, _ = model.predict(obs)\n",
    "                print(action)\n",
    "                obs, _, done ,_ = self.step(int(action))\n",
    "                img = obs['img']\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                out.write(img)\n",
    "            out.release()\n",
    "    \n",
    "    def get_statistic(self, model, num_games):\n",
    "        collision = 0\n",
    "        win = 0\n",
    "        destroyed = 0\n",
    "        loss = 0\n",
    "        for i in range(num_games):\n",
    "            obs = self.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action, _ = model.predict(obs)\n",
    "                obs, reward, done ,_ = self.step(int(action))\n",
    "                \n",
    "            if reward == -30:#win\n",
    "                collision+=1\n",
    "            elif reward == 100:# loss\n",
    "                win +=1\n",
    "            elif reward == -100:# loss\n",
    "                destroyed +=1\n",
    "            else:    #not_achieved\n",
    "                loss+=1\n",
    "        \n",
    "        print(\"Win: \",win/num_games)\n",
    "        print(\"destroyed: \", destroyed/num_games)\n",
    "        print(\"loss: \",loss/num_games)\n",
    "        print(\"collision: \",collision/num_games)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116acca-4767-4b29-abc3-30139dc31709",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc5ee6b-ba0e-4c02-a56a-95ead7d79d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv(obstacle_turn = True,\n",
    "            vizualaze     = False, \n",
    "            Total_war     = True,\n",
    "            head_velocity = 0.005,#0.005\n",
    "            num_obs       = 1, \n",
    "            num_enemy     = 1, \n",
    "            size_obs      = [50, 60],\n",
    "            rew_col       = -70,\n",
    "            rew_win       = 100,\n",
    "            inp_dim       = 500,\n",
    "            rew_defeat    = -100,\n",
    "            steps_limit   = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff641e91-2b7b-4c5c-9939-50bda378f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "batch_size = 25\n",
    "n_epochs = 2\n",
    "alpha = 0.001\n",
    "n_games = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8270a687-a630-4124-ae71-138308eaa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(n_actions=env.action_space.n, batch_size=batch_size,\n",
    "              alpha=alpha, n_epochs=n_epochs,\n",
    "              input_dims=env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89047a45-584d-4e14-9f99-181579f240ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  9990 score 283.5 avg score -97.2 time step 523505 learning_steps 5235\n",
      "episode  9991 score 30.2 avg score -92.0 time step 523553 learning_steps 5235\n",
      "episode  9992 score -370.5 avg score -94.8 time step 523586 learning_steps 5235\n",
      "episode  9993 score -70.9 avg score -95.8 time step 523624 learning_steps 5236\n",
      "episode  9994 score -46.0 avg score -96.0 time step 523668 learning_steps 5236\n",
      "episode  9995 score -433.3 avg score -99.6 time step 523742 learning_steps 5237\n",
      "episode  9996 score -71.4 avg score -99.3 time step 523754 learning_steps 5237\n",
      "episode  9997 score -127.6 avg score -98.9 time step 523777 learning_steps 5237\n",
      "episode  9998 score -351.9 avg score -101.6 time step 523817 learning_steps 5238\n",
      "episode  9999 score -642.6 avg score -103.1 time step 523889 learning_steps 5238\n"
     ]
    }
   ],
   "source": [
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "\n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    observation = np.reshape(observation, (3, 500, 500))\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        \n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        observation_ = np.reshape(observation_, (3, 500, 500))\n",
    "        \n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        agent.remember(observation, action, prob, val, reward, done)\n",
    "        if n_steps % N == 0:\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        agent.save_models()\n",
    "        \n",
    "    if not bool(i%10):clear_output()\n",
    "    print('episode ', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
    "          'time step', n_steps, 'learning_steps', learn_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5741576-a3f0-4a7d-93a0-d895e3c448a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(scores, x, figure_file):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.savefig(figure_file, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95dfe7d2-df26-4dc1-a2f0-8bca9e3a535a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10000,) and (10018,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_games)]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_learning_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPPO.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mplot_learning_curve\u001b[0;34m(scores, x, figure_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(running_avg)):\n\u001b[1;32m      4\u001b[0m     running_avg[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(scores[\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m):(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_avg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(figure_file, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:2769\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2770\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2771\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10000,) and (10018,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i + 1 for i in range(n_games)]\n",
    "plot_learning_curve( score_history,x, 'PPO.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7087e3-386b-4721-baeb-b1bf6e2c0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffaa76-3647-4a34-903c-8be196e646c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv(obstacle_turn = True,\n",
    "            vizualaze     = True, \n",
    "            Total_war     = True,\n",
    "            head_velocity = 0.005,#0.005\n",
    "            num_obs       = 1, \n",
    "            num_enemy     = 1, \n",
    "            size_obs      = [50, 60],\n",
    "            rew_col       = -70,\n",
    "            rew_win       = 100,\n",
    "            inp_dim       = 500,\n",
    "            rew_defeat    = -100,\n",
    "            steps_limit   = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fec42-1ff6-447a-b7d4-e3a38831f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    observation = env.reset()\n",
    "    observation = np.reshape(observation, (3, 500, 500))\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        \n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        observation_ = np.reshape(observation_, (3, 500, 500))\n",
    "        \n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        # agent.remember(observation, action, prob, val, reward, done)\n",
    "        # if n_steps % N == 0:\n",
    "            # agent.learn()\n",
    "            # learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    # if avg_score > best_score:\n",
    "    #     best_score = avg_score\n",
    "    #     agent.save_models()\n",
    "        \n",
    "    # if not bool(i%10):clear_output()\n",
    "    print('episode ', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
    "          'time step', n_steps, 'learning_steps', learn_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0069b-c19a-452b-992e-ea4ca39e758a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed350c5-abcc-4924-b494-41215bac8328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b6f2c-2083-40aa-9c2c-e6fef42b4307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31367946-e82b-4dc9-b228-d8444220769d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27fab0-9aa5-4102-b6bd-a5a6159d6979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82d3f9-1c26-45b2-b2af-787fe9fef4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a909c8-c828-454c-ad77-915c4a4b2dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e06598-3c6e-4c65-8187-4ed29b27e90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9046ea8-c72e-4435-b168-cb8079289f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70ddd3-eb3c-4a17-b712-b8e4612b4030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43ad90-dd74-40e4-9822-7a3db37aa6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976b264-bb40-4954-8db2-74351d7ee059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a731099-6f34-4ed5-aadf-305e2e61a342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
